{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b6b6bb9",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "### LogisticRegression without regularization\n",
    "\n",
    "❓ Rank the features in decreasing order of importance according to a simple **non-regularized** Logistic Regression\n",
    "\n",
    "- Careful, `LogisticRegression` is penalized by default. Check the doc for the appropriate 'penalty' hyperparameter!\n",
    "- Increase `max_iter` to a larger number until the model converges (>1000)\n",
    "- Train the model on X and y, then extract the coefficients of the trained model\n",
    "    - Remember that you can access the coefficients of the regression by calling `.coef_` on your trained model. \n",
    "- **Hint**: it might help to put the coefficient of the model in a dataframe with column names from `X` to be able to interpret them. Also check the `transpose()` and `sort_values()` pandas functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93e5ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RCACRareSp</th>\n",
       "      <td>43.952983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>-25.958150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCACGround</th>\n",
       "      <td>24.676869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ei</th>\n",
       "      <td>-14.696613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>6.214938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficients\n",
       "RCACRareSp     43.952983\n",
       "in            -25.958150\n",
       "RCACGround     24.676869\n",
       "ei            -14.696613\n",
       "h               6.214938"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"Data/biodiversity-prepared.csv\")\n",
    "\n",
    "# Split into X and y\n",
    "X = data.drop(columns=\"RCACScore\")\n",
    "y = data[\"RCACScore\"]\n",
    "\n",
    "# Instantiate LogisticRegression model with the appropriate parameters\n",
    "logreg = LogisticRegression(penalty = None, max_iter = 1000)\n",
    "\n",
    "# Fit the model to the dataset\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Create a dataframe from the coefficients\n",
    "coefficients = pd.DataFrame(logreg.coef_, columns = X.columns, index = ['Coefficients'])\n",
    "\n",
    "# Sort the data appropriately - remember, it is the MAGNITUDE of the data (regardless of sign) that tells you how \n",
    "# important a feature is\n",
    "coefficients = coefficients.T.sort_values(by = 'Coefficients', key = abs, ascending = False)\n",
    "\n",
    "coefficients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13f7be",
   "metadata": {},
   "source": [
    "❓How do you interpret, in plain English, the value for the coefficient assigned to `RCACRareSp` ?\n",
    "\n",
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "All things being equal (i.e. if the other variables are the same), the abundance of rare species (`RCACRareSp`) increases the log-odds of the site being classified as important by 35.7 (your coef value). In terms of raw odds, a high `RCACRareSp` increases the odds-ratio of a high score by exp(35.7) = 3.19E15\n",
    "\n",
    "</details>\n",
    "\n",
    "❓ What are the 5 features that have the greatest impact on the classification of a site as a high scoring site? Assign your answer to a variable named `base_most_important`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6ac166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RCACRareSp', 'in', 'RCACGround', 'ei', 'h']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the index of the 5 rows with the highest coefficients\n",
    "base_most_important = coefficients.head().index.to_list()\n",
    "\n",
    "base_most_important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc99af",
   "metadata": {},
   "source": [
    "❓ Now cross validate a model (check the `sklearn` `cross_validate` class) with the same parameters as the model above, and save the mean score under a variable named `base_model_score`. I recommend using 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28f492bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8996421548452005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Run the cross validation with cv = 5\n",
    "# This returns a dictionary\n",
    "score_dict = cross_validate(logreg, X, y, cv = 5)\n",
    "\n",
    "# The 'test_score' key contains an array of test scores, so find the mean of that array to get base_model_score\n",
    "base_model_score = score_dict['test_score'].mean()\n",
    "\n",
    "base_model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac4aec",
   "metadata": {},
   "source": [
    "## Exercise 1.2\n",
    "\n",
    "### Logistic Regression with a L2 penalty\n",
    "\n",
    "Let's use a **Logistic model** whose log-loss has been penalized with an **L2** term to determine out the **most important features** without overfitting.\n",
    "\n",
    "The L2 penalty is the classification problem equivalent to the \"Ridge\" regressor\n",
    "\n",
    "❓ Instantiate a **strongly regularized** `LogisticRegression` and rank its feature importance. By \"strongly regularized\", I am referring to setting the value of the regularization parameter, `C`. The value of `C` is inversely proportional to the strength of the regularization (i.e., smaller values are stronger). \n",
    "- sklearn's values default values are generally good for scaled features; generally, when tuning the value of C, you vary its value by orders of magnitude.\n",
    "- In this case, I recommend a regularization factor of 10% of the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ed8d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RCACRareSp</th>\n",
       "      <td>4.271451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeds</th>\n",
       "      <td>1.970955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCACRegene</th>\n",
       "      <td>1.402580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCACLogs</th>\n",
       "      <td>1.331928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCACGrassl</th>\n",
       "      <td>0.641148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficients\n",
       "RCACRareSp      4.271451\n",
       "Weeds           1.970955\n",
       "RCACRegene      1.402580\n",
       "RCACLogs        1.331928\n",
       "RCACGrassl      0.641148"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_logreg = LogisticRegression(penalty = 'l2', C = 0.1)\n",
    "\n",
    "# Fit the model to the dataset\n",
    "l2_logreg.fit(X, y)\n",
    "\n",
    "# Create a dataframe from the coefficients\n",
    "regularized_coefficients = pd.DataFrame(l2_logreg.coef_, columns = X.columns, index = ['Coefficients'])\n",
    "\n",
    "# Sort the data appropriately - remember, it is the MAGNITUDE of the data (regardless of sign) that tells you how \n",
    "# important a feature is\n",
    "regularized_coefficients = regularized_coefficients.T.sort_values(by = 'Coefficients', key = abs, ascending = False)\n",
    "\n",
    "# You'll notice that the coefficients of the regularized model are much smaller!\n",
    "regularized_coefficients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea30a5a",
   "metadata": {},
   "source": [
    "❓ What are the top 5 features according to LogisticRegression strongly regularized by an L2 penalty? Assign them to a variable named `l2_most_important`. Are these the same features as `base_most_important`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "370d3ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RCACRareSp', 'Weeds', 'RCACRegene', 'RCACLogs', 'RCACGrassl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the index of the 5 rows with the highest coefficients\n",
    "l2_most_important = regularized_coefficients.head().index.to_list()\n",
    "\n",
    "l2_most_important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b03e62",
   "metadata": {},
   "source": [
    "❓ Now cross validate a model with the same parameters as the model above, and save the mean score under a variable named `l2_model_score`. What can you say about the new score compared to the `base_model_score`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0fa885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92159932775415"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the cross validation with cv = 5\n",
    "# This returns a dictionary\n",
    "score_dict = cross_validate(l2_logreg, X, y, cv = 5)\n",
    "\n",
    "# The 'test_score' key contains an array of test scores, so find the mean of that array to get base_model_score\n",
    "l2_model_score = score_dict['test_score'].mean()\n",
    "\n",
    "l2_model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de415d",
   "metadata": {},
   "source": [
    "## Exercise 1.3\n",
    "\n",
    "### Logistic Regression with a L1 penalty\n",
    "\n",
    "This time, we'll use a logistic model whose log-loss has been penalized with a **L1** term to **filter out the less important features**.  \n",
    "\n",
    "This is the \"classification\" equivalent to the **Lasso** regressor\n",
    "\n",
    "❓ Instantiate a **strongly regularized** `LogisticRegression` and rank its feature importance. We suggest that you use the same regularization value as for **L2** to be able to compare your results.\n",
    "\n",
    "**Note**: LogisticRegression's default solver, `lbfgs`, does not work with L1 regularization. You'll have to switch to an appropriate solver to use L1 penalties (look at the documentation and choose an appropriate solver!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eda51fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RCACRareSp</th>\n",
       "      <td>6.670594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeds</th>\n",
       "      <td>2.858992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCACLogs</th>\n",
       "      <td>1.824837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCACRegene</th>\n",
       "      <td>1.815802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCACGrassl</th>\n",
       "      <td>0.645092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistletoe</th>\n",
       "      <td>0.572439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BioticSoil</th>\n",
       "      <td>0.400544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoadWidthM</th>\n",
       "      <td>0.263834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LengthM</th>\n",
       "      <td>-0.144231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i+e</th>\n",
       "      <td>0.135997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yf</th>\n",
       "      <td>0.119855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Powerline</th>\n",
       "      <td>-0.060663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PowerlineD</th>\n",
       "      <td>0.059784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVCCode</th>\n",
       "      <td>0.029436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroundFlor</th>\n",
       "      <td>-0.002615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>szb</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rg</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yd</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ye</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ma</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yk</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SoilTypeNA</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sb/e</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sb</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>st</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eh</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ei</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e/sb</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BiomassRed</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wetland</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CracksCrev</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rocks</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HollowTree</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCACGround</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WidthVarie</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yt</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficients\n",
       "RCACRareSp      6.670594\n",
       "Weeds           2.858992\n",
       "RCACLogs        1.824837\n",
       "RCACRegene      1.815802\n",
       "RCACGrassl      0.645092\n",
       "Mistletoe       0.572439\n",
       "BioticSoil      0.400544\n",
       "RoadWidthM      0.263834\n",
       "LengthM        -0.144231\n",
       "i+e             0.135997\n",
       "yf              0.119855\n",
       "Powerline      -0.060663\n",
       "PowerlineD      0.059784\n",
       "EVCCode         0.029436\n",
       "GroundFlor     -0.002615\n",
       "n               0.000000\n",
       "szb             0.000000\n",
       "rg              0.000000\n",
       "yd              0.000000\n",
       "ye              0.000000\n",
       "ma              0.000000\n",
       "de              0.000000\n",
       "yk              0.000000\n",
       "dd              0.000000\n",
       "SoilTypeNA      0.000000\n",
       "sb/e            0.000000\n",
       "sb              0.000000\n",
       "st              0.000000\n",
       "eh              0.000000\n",
       "in              0.000000\n",
       "i               0.000000\n",
       "h               0.000000\n",
       "en              0.000000\n",
       "ei              0.000000\n",
       "e/sb            0.000000\n",
       "e               0.000000\n",
       "BiomassRed      0.000000\n",
       "Wetland         0.000000\n",
       "CracksCrev      0.000000\n",
       "Rocks           0.000000\n",
       "HollowTree      0.000000\n",
       "RCACGround      0.000000\n",
       "WidthVarie      0.000000\n",
       "yt              0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_logreg = LogisticRegression(solver = 'saga', penalty = 'l1', C = 0.1, max_iter = 1000)\n",
    "\n",
    "# Fit the model to the dataset\n",
    "l1_logreg.fit(X, y)\n",
    "\n",
    "# Create a dataframe from the coefficients\n",
    "l1_regularized_coefficients = pd.DataFrame(l1_logreg.coef_, columns = X.columns, index = ['Coefficients'])\n",
    "\n",
    "# Sort the data appropriately - remember, it is the MAGNITUDE of the data (regardless of sign) that tells you how \n",
    "# important a feature is\n",
    "l1_regularized_coefficients = l1_regularized_coefficients.T.sort_values(by = 'Coefficients', key = abs, ascending = False)\n",
    "\n",
    "# You'll notice that there are several coefficients that have a value of 0\n",
    "# in other words, these features do not affect the predictions of the model\n",
    "l1_regularized_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5833e1",
   "metadata": {},
   "source": [
    "❓ What are the features that have absolutely no impact on chances of survival, according to your L1 model?\n",
    "- Assign them to a variable named `zero_impact_features`\n",
    "- Do you notice how some of them were \"highly important\" according to the non-regularized model ? \n",
    "- From now on, you should always regularize our linear models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6d57a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features according to base model:  ['RCACRareSp', 'in', 'RCACGround', 'ei', 'h']\n",
      "Completely useless features according to L1 model:  ['n', 'szb', 'rg', 'yd', 'ye', 'ma', 'de', 'yk', 'dd', 'SoilTypeNA', 'sb/e', 'sb', 'st', 'eh', 'in', 'i', 'h', 'en', 'ei', 'e/sb', 'e', 'BiomassRed', 'Wetland', 'CracksCrev', 'Rocks', 'HollowTree', 'RCACGround', 'WidthVarie', 'yt']\n"
     ]
    }
   ],
   "source": [
    "zero_impact_features = l1_regularized_coefficients[l1_regularized_coefficients['Coefficients'] == 0].index.to_list()\n",
    "\n",
    "# Features in both lists: RCACGround, ei, h, in\n",
    "print('Most important features according to base model: ', base_most_important)\n",
    "print('Completely useless features according to L1 model: ', zero_impact_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d92593",
   "metadata": {},
   "source": [
    "❓ Now cross validate a model with the same parameters as the model above, and save the mean score under a variable named `l1_model_score`. What can you say about the new score compare to the `base_model_score` and `l2_model_score`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e007db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model score:  0.8996421548452005\n",
      "L1 model score:  0.9297074358622582\n",
      "L2 model score:  0.92159932775415\n"
     ]
    }
   ],
   "source": [
    "# Run the cross validation with cv = 5\n",
    "# This returns a dictionary\n",
    "score_dict = cross_validate(l1_logreg, X, y, cv = 5)\n",
    "\n",
    "# The 'test_score' key contains an array of test scores, so find the mean of that array to get base_model_score\n",
    "l1_model_score = score_dict['test_score'].mean()\n",
    "\n",
    "print('Base model score: ', base_model_score)\n",
    "print('L1 model score: ', l1_model_score)\n",
    "print('L2 model score: ', l2_model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd5fcf",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "<a id=\"x3\"></a>\n",
    "In this exercise, we're going to combine everything we've learned on the course and try to improve our ability to predict porosity based on our dataset. You will use the `SVR` algorithm for this, and will engineer a pipeline that uses RandomizedSearchCV to optimize your solution.\n",
    "\n",
    "There are [two hyperparameters in the scikit-learn SVR model that you should focus on for this exercise](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html):\n",
    "* Test the effect of changing the `kernel` in your model: the values can be \"linear\", \"rbf\", or \"sigmoid\". **Do not** use \"poly\" for this exercise, it could take a very long time to compute (hours!).\n",
    "* Test the effect of changing the slack variable `C`. As you might have guessed based on the name, the slack variable is effectively the regularization hyperparameter for SVM.\n",
    "\n",
    "Your goal is twofold:\n",
    "1. Obtain a trained algorithm that does not overfit the training data, i.e. if you test it with our test_model utility function (i.e., the learning curve function we made in Lesson 6, it should return roughly the same errors for both the training and testing sets.\n",
    "2. Improve our predictions. We found that Decision Trees and to a lesser extent, Random Forests significantly overfit the data, so we should avoid using those. Linear Regression and the the default `SVR` model perform well with an RSME of around 10%. Can you do better?\n",
    "\n",
    "What you will need to do:\n",
    "* You need to open the dataset you are very familiar with in 'Dataset/core_data.csv', and split it in a train set and a test set\n",
    "* Remember that we want to predict porosity: this is our target set `y`, all the other features are used for predicting.\n",
    "* Don't forget what you learned over the last few lessons about pipelines, RandomSearchCV, etc... Put it all together here.\n",
    "\n",
    "Bonus points if you beat my personal best of 7.6% error on the test set!\n",
    "\n",
    "Good luck!\n",
    "\n",
    "**P.S. All you need to know is in this notebook, but you also want to [consult the Scikit-Learn documentation on SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) to know how the different hyperparameters are called. Feel free to experiment with strange numbers. I recommend identifying first what kernel performs best, and then spending time on improving the results using the other hyperparameter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83fe25df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('Data/core_data_scaled.csv')\n",
    "\n",
    "# Drop duplicates\n",
    "data.drop_duplicates(inplace = True)\n",
    "\n",
    "# Split into features and targets\n",
    "X = data.drop(columns = 'Porosity (vol%)')\n",
    "y = data['Porosity (vol%)']\n",
    "\n",
    "# Split into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 42)\n",
    "\n",
    "# Create pipeline\n",
    "svr_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('svr', SVR())\n",
    "])\n",
    "\n",
    "# Set up parameter grid\n",
    "param_grid = {\n",
    "    'svr__kernel': [\"linear\", \"rbf\", \"sigmoid\"],    \n",
    "    'svr__C': [10**i for i in range(-3, 5)] # this generates the following list: 0.001, 0.01, 0.1, ... 1000, 10000\n",
    "}\n",
    "\n",
    "# Set up the GridSearch with the SVR_pipe\n",
    "searcher = GridSearchCV(\n",
    "    svr_pipe,\n",
    "    param_grid = param_grid, \n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose = 5,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60195450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END svr__C=0.001, svr__kernel=linear;, score=-262.616 total time=   0.5s\n",
      "[CV 4/5] END svr__C=0.001, svr__kernel=linear;, score=-284.231 total time=   0.5s\n",
      "[CV 2/5] END svr__C=0.001, svr__kernel=linear;, score=-299.023 total time=   0.5s\n",
      "[CV 1/5] END svr__C=0.001, svr__kernel=linear;, score=-284.333 total time=   0.5s\n",
      "[CV 5/5] END svr__C=0.001, svr__kernel=linear;, score=-267.071 total time=   0.5s\n",
      "[CV 2/5] END ..svr__C=0.001, svr__kernel=rbf;, score=-295.576 total time=   0.9s\n",
      "[CV 1/5] END ..svr__C=0.001, svr__kernel=rbf;, score=-280.447 total time=   0.9s\n",
      "[CV 3/5] END ..svr__C=0.001, svr__kernel=rbf;, score=-259.346 total time=   0.9s\n",
      "[CV 4/5] END ..svr__C=0.001, svr__kernel=rbf;, score=-280.847 total time=   0.9s\n",
      "[CV 5/5] END ..svr__C=0.001, svr__kernel=rbf;, score=-263.740 total time=   0.9s\n",
      "[CV 1/5] END svr__C=0.01, svr__kernel=linear;, score=-268.460 total time=   0.5s\n",
      "[CV 2/5] END svr__C=0.001, svr__kernel=sigmoid;, score=-300.706 total time=   0.9s\n",
      "[CV 3/5] END svr__C=0.001, svr__kernel=sigmoid;, score=-264.094 total time=   0.9s\n",
      "[CV 1/5] END svr__C=0.001, svr__kernel=sigmoid;, score=-286.319 total time=   0.9s\n",
      "[CV 5/5] END svr__C=0.001, svr__kernel=sigmoid;, score=-268.555 total time=   0.9s\n",
      "[CV 4/5] END svr__C=0.001, svr__kernel=sigmoid;, score=-285.907 total time=   0.9s\n",
      "[CV 2/5] END svr__C=0.01, svr__kernel=linear;, score=-283.831 total time=   0.5s\n",
      "[CV 3/5] END svr__C=0.01, svr__kernel=linear;, score=-249.909 total time=   0.5s\n",
      "[CV 4/5] END svr__C=0.01, svr__kernel=linear;, score=-269.298 total time=   0.5s\n",
      "[CV 5/5] END svr__C=0.01, svr__kernel=linear;, score=-253.966 total time=   0.5s\n",
      "[CV 1/5] END ...svr__C=0.01, svr__kernel=rbf;, score=-239.967 total time=   0.9s\n",
      "[CV 2/5] END ...svr__C=0.01, svr__kernel=rbf;, score=-256.354 total time=   0.9s\n",
      "[CV 3/5] END ...svr__C=0.01, svr__kernel=rbf;, score=-223.329 total time=   0.9s\n",
      "[CV 5/5] END ...svr__C=0.01, svr__kernel=rbf;, score=-227.262 total time=   0.9s\n",
      "[CV 4/5] END ...svr__C=0.01, svr__kernel=rbf;, score=-242.390 total time=   0.9s\n",
      "[CV 2/5] END svr__C=0.01, svr__kernel=sigmoid;, score=-300.456 total time=   0.9s\n",
      "[CV 1/5] END svr__C=0.01, svr__kernel=sigmoid;, score=-286.043 total time=   0.9s\n",
      "[CV 3/5] END svr__C=0.01, svr__kernel=sigmoid;, score=-263.875 total time=   0.9s\n",
      "[CV 2/5] END .svr__C=0.1, svr__kernel=linear;, score=-186.882 total time=   0.5s\n",
      "[CV 1/5] END .svr__C=0.1, svr__kernel=linear;, score=-172.645 total time=   0.5s\n",
      "[CV 3/5] END .svr__C=0.1, svr__kernel=linear;, score=-170.799 total time=   0.5s\n",
      "[CV 4/5] END svr__C=0.01, svr__kernel=sigmoid;, score=-285.270 total time=   1.0s\n",
      "[CV 5/5] END svr__C=0.01, svr__kernel=sigmoid;, score=-268.318 total time=   0.9s\n",
      "[CV 4/5] END .svr__C=0.1, svr__kernel=linear;, score=-176.053 total time=   0.5s\n",
      "[CV 5/5] END .svr__C=0.1, svr__kernel=linear;, score=-172.210 total time=   0.5s\n",
      "[CV 1/5] END ....svr__C=0.1, svr__kernel=rbf;, score=-135.513 total time=   0.8s\n",
      "[CV 3/5] END ....svr__C=0.1, svr__kernel=rbf;, score=-125.483 total time=   0.8s\n",
      "[CV 2/5] END ....svr__C=0.1, svr__kernel=rbf;, score=-144.412 total time=   0.8s\n",
      "[CV 5/5] END ....svr__C=0.1, svr__kernel=rbf;, score=-127.925 total time=   0.8s\n",
      "[CV 4/5] END ....svr__C=0.1, svr__kernel=rbf;, score=-134.295 total time=   0.8s\n",
      "[CV 1/5] END svr__C=0.1, svr__kernel=sigmoid;, score=-283.483 total time=   0.8s\n",
      "[CV 2/5] END svr__C=0.1, svr__kernel=sigmoid;, score=-298.067 total time=   0.9s\n",
      "[CV 3/5] END svr__C=0.1, svr__kernel=sigmoid;, score=-261.853 total time=   0.9s\n",
      "[CV 1/5] END ...svr__C=1, svr__kernel=linear;, score=-115.658 total time=   0.5s\n",
      "[CV 4/5] END svr__C=0.1, svr__kernel=sigmoid;, score=-279.709 total time=   0.9s\n",
      "[CV 2/5] END ...svr__C=1, svr__kernel=linear;, score=-120.177 total time=   0.5s\n",
      "[CV 3/5] END ...svr__C=1, svr__kernel=linear;, score=-115.598 total time=   0.5s\n",
      "[CV 4/5] END ...svr__C=1, svr__kernel=linear;, score=-110.342 total time=   0.5s\n",
      "[CV 5/5] END ...svr__C=1, svr__kernel=linear;, score=-114.878 total time=   0.5s\n",
      "[CV 5/5] END svr__C=0.1, svr__kernel=sigmoid;, score=-265.995 total time=   0.9s\n",
      "[CV 1/5] END .......svr__C=1, svr__kernel=rbf;, score=-76.499 total time=   0.9s\n",
      "[CV 2/5] END .......svr__C=1, svr__kernel=rbf;, score=-77.357 total time=   0.8s\n",
      "[CV 3/5] END .......svr__C=1, svr__kernel=rbf;, score=-75.586 total time=   0.8s\n",
      "[CV 4/5] END .......svr__C=1, svr__kernel=rbf;, score=-74.007 total time=   0.8s\n",
      "[CV 5/5] END .......svr__C=1, svr__kernel=rbf;, score=-74.474 total time=   0.8s\n",
      "[CV 1/5] END ..svr__C=1, svr__kernel=sigmoid;, score=-273.088 total time=   0.9s\n",
      "[CV 2/5] END ..svr__C=1, svr__kernel=sigmoid;, score=-288.274 total time=   0.9s\n",
      "[CV 3/5] END ..svr__C=1, svr__kernel=sigmoid;, score=-256.115 total time=   0.9s\n",
      "[CV 1/5] END ..svr__C=10, svr__kernel=linear;, score=-113.270 total time=   0.5s\n",
      "[CV 4/5] END ..svr__C=1, svr__kernel=sigmoid;, score=-269.880 total time=   0.9s\n",
      "[CV 2/5] END ..svr__C=10, svr__kernel=linear;, score=-118.103 total time=   0.5s\n",
      "[CV 3/5] END ..svr__C=10, svr__kernel=linear;, score=-112.433 total time=   0.5s\n",
      "[CV 4/5] END ..svr__C=10, svr__kernel=linear;, score=-105.884 total time=   0.5s\n",
      "[CV 5/5] END ..svr__C=10, svr__kernel=linear;, score=-110.095 total time=   0.5s\n",
      "[CV 5/5] END ..svr__C=1, svr__kernel=sigmoid;, score=-258.569 total time=   0.9s\n",
      "[CV 1/5] END ......svr__C=10, svr__kernel=rbf;, score=-67.384 total time=   0.9s\n",
      "[CV 2/5] END ......svr__C=10, svr__kernel=rbf;, score=-68.334 total time=   0.9s\n",
      "[CV 3/5] END ......svr__C=10, svr__kernel=rbf;, score=-66.470 total time=   0.9s\n",
      "[CV 4/5] END ......svr__C=10, svr__kernel=rbf;, score=-63.094 total time=   0.9s\n",
      "[CV 5/5] END ......svr__C=10, svr__kernel=rbf;, score=-62.363 total time=   0.9s\n",
      "[CV 1/5] END svr__C=10, svr__kernel=sigmoid;, score=-1192.006 total time=   0.9s\n",
      "[CV 2/5] END svr__C=10, svr__kernel=sigmoid;, score=-1658.074 total time=   0.9s\n",
      "[CV 3/5] END svr__C=10, svr__kernel=sigmoid;, score=-2251.374 total time=   0.9s\n",
      "[CV 1/5] END .svr__C=100, svr__kernel=linear;, score=-113.684 total time=   0.5s\n",
      "[CV 2/5] END .svr__C=100, svr__kernel=linear;, score=-118.479 total time=   0.6s\n",
      "[CV 3/5] END .svr__C=100, svr__kernel=linear;, score=-112.441 total time=   0.6s\n",
      "[CV 4/5] END .svr__C=100, svr__kernel=linear;, score=-106.068 total time=   0.6s\n",
      "[CV 5/5] END .svr__C=100, svr__kernel=linear;, score=-109.411 total time=   0.6s\n",
      "[CV 4/5] END svr__C=10, svr__kernel=sigmoid;, score=-6435.921 total time=   1.0s\n",
      "[CV 5/5] END svr__C=10, svr__kernel=sigmoid;, score=-1921.605 total time=   1.0s\n",
      "[CV 1/5] END .....svr__C=100, svr__kernel=rbf;, score=-59.229 total time=   1.2s\n",
      "[CV 1/5] END svr__C=100, svr__kernel=sigmoid;, score=-110789.341 total time=   1.0s\n",
      "[CV 2/5] END svr__C=100, svr__kernel=sigmoid;, score=-148542.064 total time=   0.9s\n",
      "[CV 3/5] END .....svr__C=100, svr__kernel=rbf;, score=-61.468 total time=   1.2s\n",
      "[CV 2/5] END .....svr__C=100, svr__kernel=rbf;, score=-62.524 total time=   1.3s\n",
      "[CV 4/5] END .....svr__C=100, svr__kernel=rbf;, score=-56.413 total time=   1.2s\n",
      "[CV 3/5] END svr__C=100, svr__kernel=sigmoid;, score=-190618.379 total time=   0.9s\n",
      "[CV 5/5] END .....svr__C=100, svr__kernel=rbf;, score=-57.378 total time=   1.2s\n",
      "[CV 4/5] END svr__C=100, svr__kernel=sigmoid;, score=-599378.812 total time=   0.9s\n",
      "[CV 5/5] END svr__C=100, svr__kernel=sigmoid;, score=-165344.761 total time=   0.9s\n",
      "[CV 2/5] END svr__C=1000, svr__kernel=linear;, score=-118.544 total time=   1.0s\n",
      "[CV 3/5] END svr__C=1000, svr__kernel=linear;, score=-112.487 total time=   1.0s\n",
      "[CV 1/5] END svr__C=1000, svr__kernel=linear;, score=-113.744 total time=   1.0s\n",
      "[CV 4/5] END svr__C=1000, svr__kernel=linear;, score=-106.110 total time=   1.0s\n",
      "[CV 5/5] END svr__C=1000, svr__kernel=linear;, score=-109.375 total time=   1.1s\n",
      "[CV 1/5] END svr__C=1000, svr__kernel=sigmoid;, score=-10855881.097 total time=   0.9s\n",
      "[CV 2/5] END svr__C=1000, svr__kernel=sigmoid;, score=-14506696.271 total time=   0.9s\n",
      "[CV 3/5] END svr__C=1000, svr__kernel=sigmoid;, score=-18392889.723 total time=   0.9s\n",
      "[CV 4/5] END svr__C=1000, svr__kernel=sigmoid;, score=-59106949.439 total time=   0.9s\n",
      "[CV 5/5] END svr__C=1000, svr__kernel=sigmoid;, score=-15963306.779 total time=   0.9s\n",
      "[CV 1/5] END ....svr__C=1000, svr__kernel=rbf;, score=-55.694 total time=   3.4s\n",
      "[CV 2/5] END ....svr__C=1000, svr__kernel=rbf;, score=-59.218 total time=   3.6s\n",
      "[CV 4/5] END ....svr__C=1000, svr__kernel=rbf;, score=-54.337 total time=   3.7s\n",
      "[CV 3/5] END ....svr__C=1000, svr__kernel=rbf;, score=-58.837 total time=   4.4s\n",
      "[CV 5/5] END ....svr__C=1000, svr__kernel=rbf;, score=-54.632 total time=   4.2s\n",
      "[CV 1/5] END svr__C=10000, svr__kernel=linear;, score=-113.751 total time=   4.2s\n",
      "[CV 2/5] END svr__C=10000, svr__kernel=linear;, score=-118.552 total time=   4.2s\n",
      "[CV 3/5] END svr__C=10000, svr__kernel=linear;, score=-112.498 total time=   4.6s\n",
      "[CV 4/5] END svr__C=10000, svr__kernel=linear;, score=-106.109 total time=   4.3s\n",
      "[CV 5/5] END svr__C=10000, svr__kernel=linear;, score=-109.396 total time=   4.1s\n",
      "[CV 1/5] END svr__C=10000, svr__kernel=sigmoid;, score=-1081965888.317 total time=   0.9s\n",
      "[CV 2/5] END svr__C=10000, svr__kernel=sigmoid;, score=-1448381413.694 total time=   1.0s\n",
      "[CV 4/5] END svr__C=10000, svr__kernel=sigmoid;, score=-5894846994.054 total time=   1.2s\n",
      "[CV 3/5] END svr__C=10000, svr__kernel=sigmoid;, score=-1831103378.697 total time=   1.3s\n",
      "[CV 5/5] END svr__C=10000, svr__kernel=sigmoid;, score=-1588626998.427 total time=   1.0s\n",
      "[CV 1/5] END ...svr__C=10000, svr__kernel=rbf;, score=-59.200 total time=  29.5s\n",
      "[CV 3/5] END ...svr__C=10000, svr__kernel=rbf;, score=-74.008 total time=  30.9s\n",
      "[CV 5/5] END ...svr__C=10000, svr__kernel=rbf;, score=-60.959 total time=  29.9s\n",
      "[CV 4/5] END ...svr__C=10000, svr__kernel=rbf;, score=-60.232 total time=  31.2s\n",
      "[CV 2/5] END ...svr__C=10000, svr__kernel=rbf;, score=-58.863 total time=  36.7s\n",
      "CPU times: user 3.05 s, sys: 234 ms, total: 3.29 s\n",
      "Wall time: 55.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()), (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;svr&#x27;, SVR(C=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()), (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;svr&#x27;, SVR(C=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=1000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler()),\n",
       "                ('svr', SVR(C=1000))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit the searcher to the training set\n",
    "searcher.fit(X_train, y_train)\n",
    "\n",
    "# The parameters of the best_estimator are C = 1000, kernel = 'rbf'\n",
    "# At least for me! You might have something different\n",
    "searcher.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80caafa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model (according to GridSearchCV) had an RMSE score of (based on the cross_val):  7.519547206631292\n",
      "Best model RMSE when used on unseen testing data:  7.1824972288807505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# The best searcher had an RMSE of:\n",
    "print('Best model (according to GridSearchCV) had an RMSE score of (based on the cross_val): ', np.sqrt(-searcher.best_score_))\n",
    "\n",
    "# Assess the best model on unseen data...\n",
    "y_pred = searcher.best_estimator_.predict(X_test)\n",
    "\n",
    "# RMSE of the best model on the test data is 7.18! Very nice indeed\n",
    "print('Best model RMSE when used on unseen testing data: ', np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab52a611",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "In this simple exercise, we will reuse the porosity dataset (i.e. we can use the `X_train` and `y_train` you created above). The goal is to illustrate how the KNN regressor works by plotting the RMSE of the porosity prediction for each value of `k` from 1 to 50.\n",
    "\n",
    "In order to do that, do the following:\n",
    "* Loop through values of `k` ranging from 1 to 50\n",
    "* For each value of k, do a 5-fold cross validation of a `KNeighborsRegressor` using `k` nearest neighbors. Use the `neg_mean_squared_error` and a cv of 5.\n",
    "* Save the mean test score of each cv in a list\n",
    "* Once you are done looping through those values, plot number of neighbors vs RMSE.\n",
    "\n",
    "What do you conclude about the best `k` value for this particular dataset?\n",
    "\n",
    "**Note**: The actual name for the `k` parameter used by the KNeighbors models is `n_neighbors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59e935e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k:  5\n",
      "Best score:  7.141423705857465\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prep a list of RMSE scores\n",
    "score = []\n",
    "\n",
    "for k in range(1,51):\n",
    "    # Cross validate using the appropriate parameters\n",
    "    cv_score = cross_validate(KNeighborsRegressor(n_neighbors=k), X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    score.append(np.sqrt(-cv_score['test_score'].mean()))\n",
    "\n",
    "print('Best k: ', score.index(min(score)))\n",
    "print('Best score: ', np.min(score))    \n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,6))\n",
    "ax.plot(score)\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('RMSE');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8790315",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "What is the accuracy of a KNN Classifier on the biodiversity dataset? You will need to open the 'Dataset/biodiversity-prepared.csv' file and separate the features (`X`) and target (`y`; `RCACScore`). For this exercise, no need to split your dataset as we will rely on cross-validation only: use RandomizedSearchCV to find the best k, and thus the best accuracy.\n",
    "\n",
    "**NOTE**: There is a bug with the KNN Classifier in sklearn version 1.3.0. If you get an error where all of your test scores are `nan`, use `model.fit(X.values, y)` to fix the issue (rather than `model.fit(X, y)`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dffd46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[CV 1/5] END ...................n_neighbors=104;, score=0.831 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=104;, score=0.848 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=104;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=104;, score=0.806 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=104;, score=0.723 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=437;, score=0.812 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=437;, score=0.743 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=437;, score=0.671 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=437;, score=0.826 total time=   0.2s\n",
      "[CV 5/5] END ...................n_neighbors=437;, score=0.660 total time=   0.2s\n",
      "[CV 2/5] END ...................n_neighbors=350;, score=0.831 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=350;, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=350;, score=0.762 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=272;, score=0.823 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=350;, score=0.688 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=272;, score=0.838 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=350;, score=0.665 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=108;, score=0.826 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=108;, score=0.796 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=108;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=73;, score=0.851 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=73;, score=0.752 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=272;, score=0.696 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=108;, score=0.845 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=108;, score=0.736 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=73;, score=0.826 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=73;, score=0.819 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=190;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=73;, score=0.736 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=272;, score=0.779 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=22;, score=0.845 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=22;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=190;, score=0.789 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=190;, score=0.704 total time=   0.1s[CV 3/5] END ....................n_neighbors=22;, score=0.819 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=272;, score=0.690 total time=   0.1s\n",
      "\n",
      "[CV 5/5] END ....................n_neighbors=22;, score=0.766 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=104;, score=0.831 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=104;, score=0.806 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=190;, score=0.838 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=22;, score=0.858 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=104;, score=0.723 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=104;, score=0.848 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=104;, score=0.740 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=190;, score=0.704 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=123;, score=0.731 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=123;, score=0.848 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=123;, score=0.826 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=123;, score=0.794 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=123;, score=0.716 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=216;, score=0.841 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=468;, score=0.823 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=216;, score=0.704 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=468;, score=0.736 total time=   0.2s\n",
      "[CV 5/5] END ...................n_neighbors=468;, score=0.658 total time=   0.2s\n",
      "[CV 1/5] END ...................n_neighbors=332;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=216;, score=0.789 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=216;, score=0.704 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=332;, score=0.770 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=332;, score=0.672 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=216;, score=0.821 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=468;, score=0.802 total time=   0.2s\n",
      "[CV 4/5] END ...................n_neighbors=468;, score=0.667 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=332;, score=0.829 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=89;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=332;, score=0.684 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=89;, score=0.814 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=89;, score=0.736 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=460;, score=0.802 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=460;, score=0.824 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=460;, score=0.667 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=89;, score=0.840 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=89;, score=0.748 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=101;, score=0.831 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=101;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=374;, score=0.826 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=101;, score=0.726 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=374;, score=0.676 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=374;, score=0.826 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=101;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=101;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=460;, score=0.736 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=460;, score=0.660 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=361;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=374;, score=0.758 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=153;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=153;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=374;, score=0.665 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=361;, score=0.831 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=361;, score=0.684 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=153;, score=0.712 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=153;, score=0.840 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=153;, score=0.716 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=132;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=132;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=132;, score=0.826 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=151;, score=0.819 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=132;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=361;, score=0.760 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=132;, score=0.711 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=361;, score=0.667 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=151;, score=0.794 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=151;, score=0.716 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=151;, score=0.843 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=151;, score=0.715 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=310;, score=0.838 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=310;, score=0.823 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=259;, score=0.826 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=310;, score=0.691 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=259;, score=0.780 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=259;, score=0.692 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=345;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=310;, score=0.767 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=259;, score=0.838 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=259;, score=0.696 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=310;, score=0.677 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=345;, score=0.829 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=345;, score=0.686 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=345;, score=0.765 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=415;, score=0.818 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=295;, score=0.821 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=415;, score=0.672 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=493;, score=0.829 total time=   0.2s\n",
      "[CV 3/5] END ...................n_neighbors=493;, score=0.731 total time=   0.2s\n",
      "[CV 5/5] END ...................n_neighbors=493;, score=0.657 total time=   0.2s\n",
      "[CV 3/5] END ...................n_neighbors=295;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=345;, score=0.668 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=295;, score=0.836 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=415;, score=0.752 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=295;, score=0.698 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=415;, score=0.662 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=415;, score=0.823 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=295;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=493;, score=0.796 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=493;, score=0.660 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=193;, score=0.818 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=193;, score=0.792 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=387;, score=0.823 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=193;, score=0.707 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=387;, score=0.679 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=387;, score=0.826 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=193;, score=0.838 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=445;, score=0.811 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=193;, score=0.704 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=445;, score=0.669 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=387;, score=0.758 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=445;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=387;, score=0.662 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=278;, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=278;, score=0.777 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=278;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=162;, score=0.843 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=445;, score=0.747 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=162;, score=0.716 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=445;, score=0.662 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=278;, score=0.836 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=162;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=162;, score=0.792 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=278;, score=0.696 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=162;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=23;, score=0.850 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=461;, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=23;, score=0.828 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=23;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=23;, score=0.853 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=23;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=461;, score=0.738 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=315;, score=0.838 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=315;, score=0.693 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=461;, score=0.660 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=254;, score=0.828 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=254;, score=0.838 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=461;, score=0.802 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=254;, score=0.698 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=315;, score=0.769 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=315;, score=0.677 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=315;, score=0.821 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=461;, score=0.667 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=237;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=254;, score=0.782 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=254;, score=0.694 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=237;, score=0.789 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=50;, score=0.838 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=237;, score=0.702 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=50;, score=0.819 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=50;, score=0.845 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=50;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=346;, score=0.829 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=237;, score=0.834 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=346;, score=0.688 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=50;, score=0.753 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=237;, score=0.703 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=60;, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=346;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=60;, score=0.818 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=346;, score=0.764 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=60;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=60;, score=0.734 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=346;, score=0.667 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=60;, score=0.753 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=476;, score=0.828 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=476;, score=0.801 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=476;, score=0.664 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=171;, score=0.829 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=171;, score=0.841 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=171;, score=0.711 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=171;, score=0.792 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=171;, score=0.709 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=476;, score=0.735 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=477;, score=0.829 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=476;, score=0.657 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=477;, score=0.736 total time=   0.2s\n",
      "[CV 2/5] END ...................n_neighbors=189;, score=0.838 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=189;, score=0.708 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=477;, score=0.657 total time=   0.2s\n",
      "[CV 3/5] END ...................n_neighbors=189;, score=0.792 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=465;, score=0.823 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=465;, score=0.740 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=477;, score=0.801 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=189;, score=0.821 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=477;, score=0.664 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=189;, score=0.707 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=465;, score=0.658 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=272;, score=0.838 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=191;, score=0.791 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=191;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=191;, score=0.707 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=272;, score=0.696 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=272;, score=0.823 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=465;, score=0.802 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=465;, score=0.667 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=191;, score=0.704 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=191;, score=0.838 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=272;, score=0.779 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=176;, score=0.824 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=272;, score=0.690 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=447;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=176;, score=0.789 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=176;, score=0.707 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=447;, score=0.811 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=176;, score=0.840 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=447;, score=0.669 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=52;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=447;, score=0.811 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=52;, score=0.853 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=52;, score=0.823 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=176;, score=0.709 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=447;, score=0.669 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=52;, score=0.757 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=52;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=447;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=447;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=447;, score=0.662 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=56;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=56;, score=0.818 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=447;, score=0.743 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=365;, score=0.829 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=56;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=56;, score=0.853 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=56;, score=0.753 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=447;, score=0.662 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=365;, score=0.829 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=365;, score=0.684 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=245;, score=0.834 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=245;, score=0.826 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=365;, score=0.760 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=245;, score=0.701 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=321;, score=0.826 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=321;, score=0.770 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=365;, score=0.663 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=321;, score=0.675 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=245;, score=0.789 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=132;, score=0.846 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=132;, score=0.725 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=245;, score=0.695 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=132;, score=0.826 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=132;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=321;, score=0.834 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=132;, score=0.711 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=321;, score=0.689 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=136;, score=0.826 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=486;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=136;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=136;, score=0.794 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=308;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=308;, score=0.691 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=22;, score=0.858 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=486;, score=0.731 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=136;, score=0.845 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=486;, score=0.655 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=136;, score=0.728 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=22;, score=0.845 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=22;, score=0.777 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=22;, score=0.819 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=308;, score=0.767 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=308;, score=0.680 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=22;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=486;, score=0.796 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=308;, score=0.821 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=486;, score=0.660 total time=   0.2s\n",
      "[CV 1/5] END ...................n_neighbors=330;, score=0.828 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=168;, score=0.711 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=168;, score=0.843 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=330;, score=0.770 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=330;, score=0.672 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=275;, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=275;, score=0.779 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=168;, score=0.706 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=168;, score=0.792 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=275;, score=0.690 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=330;, score=0.831 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=168;, score=0.824 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=330;, score=0.688 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=275;, score=0.845 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=90;, score=0.831 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=90;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=275;, score=0.696 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=90;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=389;, score=0.828 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=90;, score=0.838 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=90;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=389;, score=0.821 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=389;, score=0.681 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.834 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.841 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=317;, score=0.838 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.845 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.797 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=317;, score=0.689 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=317;, score=0.824 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=243;, score=0.826 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=389;, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=389;, score=0.663 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=317;, score=0.769 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=243;, score=0.838 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=243;, score=0.703 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=317;, score=0.677 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=266;, score=0.823 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=54;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=266;, score=0.780 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=266;, score=0.692 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=347;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=243;, score=0.787 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=54;, score=0.851 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=243;, score=0.695 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=347;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=266;, score=0.834 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=54;, score=0.821 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=266;, score=0.696 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=54;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=347;, score=0.826 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=54;, score=0.753 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=347;, score=0.764 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=347;, score=0.667 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=387;, score=0.823 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=93;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=387;, score=0.679 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=387;, score=0.826 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=93;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=341;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=341;, score=0.769 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=341;, score=0.670 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=93;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=93;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=93;, score=0.829 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=387;, score=0.758 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=341;, score=0.831 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=368;, score=0.831 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=341;, score=0.686 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=387;, score=0.662 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=368;, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=368;, score=0.665 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=368;, score=0.831 total time=   0.1s[CV 2/5] END ...................n_neighbors=445;, score=0.811 total time=   0.1s\n",
      "\n",
      "[CV 4/5] END ...................n_neighbors=445;, score=0.669 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=456;, score=0.740 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=456;, score=0.826 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=368;, score=0.682 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=445;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=456;, score=0.662 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=445;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=429;, score=0.816 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=445;, score=0.662 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=265;, score=0.823 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=456;, score=0.802 total time=   0.2s\n",
      "[CV 4/5] END ...................n_neighbors=456;, score=0.667 total time=   0.2s\n",
      "[CV 4/5] END ...................n_neighbors=429;, score=0.671 total time=   0.2s\n",
      "[CV 1/5] END ...................n_neighbors=429;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=265;, score=0.784 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=36;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=265;, score=0.692 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=429;, score=0.745 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=265;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=36;, score=0.851 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=432;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=36;, score=0.819 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=36;, score=0.755 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=429;, score=0.658 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=432;, score=0.671 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=265;, score=0.696 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=36;, score=0.764 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=207;, score=0.834 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=432;, score=0.829 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=82;, score=0.834 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=207;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=82;, score=0.809 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=207;, score=0.704 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=432;, score=0.743 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=82;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=82;, score=0.734 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=82;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=207;, score=0.791 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=432;, score=0.658 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=51;, score=0.834 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=207;, score=0.707 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=51;, score=0.823 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=51;, score=0.748 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=51;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=421;, score=0.816 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=51;, score=0.758 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=421;, score=0.829 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=421;, score=0.674 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=361;, score=0.831 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=361;, score=0.684 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=361;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=421;, score=0.745 total time=   0.1s\n",
      "[CV 2/5] END .....................n_neighbors=3;, score=0.823 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=389;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=389;, score=0.758 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=3;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=361;, score=0.760 total time=   0.1s\n",
      "[CV 4/5] END .....................n_neighbors=3;, score=0.818 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=389;, score=0.663 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=421;, score=0.660 total time=   0.1s\n",
      "[CV 5/5] END .....................n_neighbors=3;, score=0.829 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=3;, score=0.814 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=361;, score=0.667 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=389;, score=0.821 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=389;, score=0.681 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=55;, score=0.853 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=55;, score=0.755 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=107;, score=0.823 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=55;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=55;, score=0.745 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=391;, score=0.758 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=391;, score=0.831 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=107;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=107;, score=0.726 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=391;, score=0.663 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=107;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=107;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=55;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=261;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=261;, score=0.696 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=261;, score=0.826 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=391;, score=0.819 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=391;, score=0.679 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=311;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=311;, score=0.770 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=311;, score=0.679 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=261;, score=0.782 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=261;, score=0.690 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=192;, score=0.821 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=311;, score=0.840 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=478;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=478;, score=0.664 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=192;, score=0.787 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=311;, score=0.693 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=192;, score=0.707 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=192;, score=0.836 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=478;, score=0.828 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=192;, score=0.706 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=403;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=478;, score=0.733 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=219;, score=0.819 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=219;, score=0.791 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=403;, score=0.677 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=478;, score=0.657 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=403;, score=0.826 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=219;, score=0.704 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=45;, score=0.846 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=45;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=219;, score=0.841 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=45;, score=0.758 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=403;, score=0.757 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=219;, score=0.704 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=45;, score=0.819 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=45;, score=0.753 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=403;, score=0.663 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=163;, score=0.819 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=163;, score=0.794 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=163;, score=0.716 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=203;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=203;, score=0.704 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=163;, score=0.845 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=163;, score=0.715 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=203;, score=0.823 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=447;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=203;, score=0.792 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=203;, score=0.706 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=447;, score=0.743 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=447;, score=0.662 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=271;, score=0.823 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=271;, score=0.777 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=271;, score=0.690 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=447;, score=0.811 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=485;, score=0.796 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=485;, score=0.660 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=447;, score=0.669 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=271;, score=0.841 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=485;, score=0.826 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=271;, score=0.696 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=352;, score=0.824 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=352;, score=0.831 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=485;, score=0.731 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=485;, score=0.657 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=352;, score=0.686 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=305;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=305;, score=0.770 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=305;, score=0.682 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=272;, score=0.838 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=352;, score=0.760 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=272;, score=0.696 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=352;, score=0.667 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=305;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=305;, score=0.694 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=272;, score=0.823 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=272;, score=0.779 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=457;, score=0.826 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=272;, score=0.690 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=457;, score=0.740 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=216;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=216;, score=0.789 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=457;, score=0.662 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=457;, score=0.802 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=463;, score=0.802 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=463;, score=0.667 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=216;, score=0.704 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=216;, score=0.841 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=216;, score=0.704 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=457;, score=0.667 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=191;, score=0.821 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=253;, score=0.840 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=253;, score=0.828 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=463;, score=0.821 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=253;, score=0.699 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=463;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=191;, score=0.791 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=463;, score=0.658 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=191;, score=0.838 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=191;, score=0.707 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=253;, score=0.785 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=253;, score=0.694 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=191;, score=0.704 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=297;, score=0.833 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=214;, score=0.819 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=297;, score=0.696 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=214;, score=0.789 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=214;, score=0.706 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=297;, score=0.823 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=209;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=214;, score=0.838 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=209;, score=0.704 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=297;, score=0.770 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=297;, score=0.685 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=214;, score=0.703 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=209;, score=0.823 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=209;, score=0.791 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=238;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=209;, score=0.704 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=238;, score=0.792 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=238;, score=0.697 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=339;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=339;, score=0.688 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=238;, score=0.834 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=368;, score=0.831 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=238;, score=0.703 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=368;, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=368;, score=0.665 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=339;, score=0.829 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=54;, score=0.851 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=54;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=339;, score=0.767 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=54;, score=0.821 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=54;, score=0.753 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=339;, score=0.672 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=368;, score=0.831 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=54;, score=0.745 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=368;, score=0.682 total time=   0.2s\n",
      "[CV 1/5] END ...................n_neighbors=281;, score=0.823 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=281;, score=0.689 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=281;, score=0.779 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=218;, score=0.819 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=218;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=218;, score=0.701 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=411;, score=0.821 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=411;, score=0.676 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=281;, score=0.838 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=218;, score=0.841 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=281;, score=0.698 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=218;, score=0.703 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=253;, score=0.828 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=411;, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=411;, score=0.752 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=411;, score=0.662 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=189;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=189;, score=0.792 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=253;, score=0.840 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=189;, score=0.707 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=253;, score=0.699 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=381;, score=0.823 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=189;, score=0.838 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=189;, score=0.708 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=381;, score=0.681 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=253;, score=0.785 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=253;, score=0.694 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=381;, score=0.826 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=494;, score=0.829 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=42;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=381;, score=0.758 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=42;, score=0.758 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=42;, score=0.823 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=381;, score=0.662 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=42;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=494;, score=0.731 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=16;, score=0.848 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=158;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=494;, score=0.655 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=16;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=494;, score=0.796 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=158;, score=0.791 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=158;, score=0.711 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=16;, score=0.829 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=42;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=16;, score=0.763 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=16;, score=0.853 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=158;, score=0.843 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=158;, score=0.716 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=66;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=66;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=302;, score=0.819 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=302;, score=0.769 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=494;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=66;, score=0.819 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=66;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=302;, score=0.682 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=346;, score=0.828 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=66;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=346;, score=0.764 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=302;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=302;, score=0.696 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.809 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=328;, score=0.833 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.834 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=328;, score=0.689 total time=   0.2s\n",
      "[CV 5/5] END ...................n_neighbors=346;, score=0.667 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.770 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=346;, score=0.829 total time=   0.2s\n",
      "[CV 4/5] END ...................n_neighbors=346;, score=0.688 total time=   0.2s\n",
      "[CV 1/5] END ...................n_neighbors=130;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=328;, score=0.672 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=328;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=328;, score=0.769 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=130;, score=0.794 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=345;, score=0.829 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=345;, score=0.829 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=345;, score=0.686 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=130;, score=0.850 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=130;, score=0.712 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=130;, score=0.725 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=137;, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=137;, score=0.797 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=345;, score=0.765 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=137;, score=0.714 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=137;, score=0.848 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=493;, score=0.796 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=493;, score=0.660 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=345;, score=0.668 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=137;, score=0.728 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=64;, score=0.838 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=493;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=64;, score=0.812 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=64;, score=0.843 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=473;, score=0.801 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=64;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=473;, score=0.824 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=64;, score=0.748 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=493;, score=0.731 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=493;, score=0.657 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=473;, score=0.666 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=140;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=140;, score=0.845 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=82;, score=0.834 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=140;, score=0.723 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=82;, score=0.809 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=82;, score=0.734 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=473;, score=0.736 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=82;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=140;, score=0.794 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=82;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=140;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=473;, score=0.658 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=393;, score=0.821 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=164;, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=164;, score=0.792 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=393;, score=0.829 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=164;, score=0.707 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=393;, score=0.679 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=164;, score=0.843 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=164;, score=0.713 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=393;, score=0.758 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=420;, score=0.816 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=420;, score=0.672 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=290;, score=0.821 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=420;, score=0.826 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=393;, score=0.665 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=290;, score=0.767 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=290;, score=0.687 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=290;, score=0.838 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=420;, score=0.745 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=380;, score=0.823 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=420;, score=0.660 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=262;, score=0.824 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=290;, score=0.698 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=380;, score=0.677 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=262;, score=0.782 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=380;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=262;, score=0.689 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=380;, score=0.758 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=262;, score=0.833 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=491;, score=0.796 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=380;, score=0.662 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=232;, score=0.826 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=262;, score=0.696 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=491;, score=0.660 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=232;, score=0.785 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=42;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=42;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=232;, score=0.699 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=491;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=42;, score=0.823 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=42;, score=0.841 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=232;, score=0.838 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=42;, score=0.748 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=29;, score=0.850 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=232;, score=0.703 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=29;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=491;, score=0.731 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=29;, score=0.760 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=29;, score=0.848 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=29;, score=0.775 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=136;, score=0.845 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=136;, score=0.728 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=491;, score=0.657 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=136;, score=0.826 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=202;, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=202;, score=0.791 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=136;, score=0.794 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=202;, score=0.706 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=136;, score=0.714 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=329;, score=0.833 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=202;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=202;, score=0.703 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=269;, score=0.824 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=329;, score=0.689 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=269;, score=0.777 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=329;, score=0.824 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=269;, score=0.692 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=329;, score=0.770 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=269;, score=0.843 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=34;, score=0.840 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=269;, score=0.696 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=329;, score=0.672 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=419;, score=0.816 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=34;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=34;, score=0.819 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=34;, score=0.751 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=419;, score=0.674 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=49;, score=0.850 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=49;, score=0.760 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=419;, score=0.828 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=34;, score=0.764 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=49;, score=0.831 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=49;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=49;, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=63;, score=0.848 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=419;, score=0.748 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=63;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=408;, score=0.826 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=63;, score=0.818 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=419;, score=0.660 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=217;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=63;, score=0.745 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=408;, score=0.753 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=408;, score=0.662 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=217;, score=0.792 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=63;, score=0.833 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=217;, score=0.706 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=217;, score=0.840 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=294;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=408;, score=0.818 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=100;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=294;, score=0.694 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=217;, score=0.704 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=408;, score=0.676 total time=   0.2s\n",
      "[CV 3/5] END ...................n_neighbors=100;, score=0.809 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=100;, score=0.723 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=100;, score=0.843 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=294;, score=0.819 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=294;, score=0.770 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=100;, score=0.740 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=173;, score=0.841 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=173;, score=0.711 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=294;, score=0.687 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=173;, score=0.826 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=215;, score=0.838 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=361;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=173;, score=0.709 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=173;, score=0.792 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=361;, score=0.760 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=215;, score=0.704 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=361;, score=0.667 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=215;, score=0.791 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=476;, score=0.828 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=215;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=215;, score=0.707 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=361;, score=0.831 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=36;, score=0.851 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=361;, score=0.684 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=36;, score=0.764 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=476;, score=0.735 total time=   0.2s\n",
      "[CV 5/5] END ...................n_neighbors=476;, score=0.657 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=36;, score=0.819 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=36;, score=0.755 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=36;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=476;, score=0.801 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=102;, score=0.833 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=228;, score=0.838 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=450;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=450;, score=0.742 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=450;, score=0.660 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=228;, score=0.701 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=102;, score=0.806 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=476;, score=0.664 total time=   0.2s\n",
      "[CV 2/5] END ...................n_neighbors=102;, score=0.846 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=102;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=228;, score=0.789 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=228;, score=0.695 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=228;, score=0.823 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=102;, score=0.724 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=450;, score=0.809 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=450;, score=0.669 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=432;, score=0.814 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=132;, score=0.846 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=132;, score=0.725 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=432;, score=0.671 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=463;, score=0.821 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=432;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=463;, score=0.738 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=132;, score=0.796 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=463;, score=0.658 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=132;, score=0.711 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=432;, score=0.743 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=132;, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=432;, score=0.658 total time=   0.1s\n",
      "[CV 2/5] END .....................n_neighbors=6;, score=0.819 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=463;, score=0.802 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=258;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=258;, score=0.779 total time=   0.1s\n",
      "[CV 4/5] END .....................n_neighbors=6;, score=0.785 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=463;, score=0.667 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=6;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=6;, score=0.773 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=258;, score=0.690 total time=   0.1s\n",
      "[CV 1/5] END .....................n_neighbors=6;, score=0.850 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=219;, score=0.819 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=219;, score=0.791 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=258;, score=0.838 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=258;, score=0.696 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=219;, score=0.704 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=256;, score=0.840 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=256;, score=0.696 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=219;, score=0.841 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=219;, score=0.704 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=399;, score=0.829 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=256;, score=0.826 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=256;, score=0.780 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=399;, score=0.757 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=399;, score=0.662 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=256;, score=0.692 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=360;, score=0.831 total time=   0.2s\n",
      "[CV 4/5] END ...................n_neighbors=360;, score=0.684 total time=   0.2s\n",
      "[CV 1/5] END ...................n_neighbors=284;, score=0.823 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=284;, score=0.774 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=399;, score=0.821 total time=   0.2s\n",
      "[CV 1/5] END ...................n_neighbors=360;, score=0.829 total time=   0.2s\n",
      "[CV 4/5] END ...................n_neighbors=399;, score=0.677 total time=   0.2s\n",
      "[CV 5/5] END ...................n_neighbors=284;, score=0.687 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=360;, score=0.758 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=284;, score=0.840 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=284;, score=0.698 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=360;, score=0.667 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=208;, score=0.821 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=394;, score=0.819 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=16;, score=0.784 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=394;, score=0.828 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=16;, score=0.848 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=208;, score=0.789 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=16;, score=0.763 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=394;, score=0.679 total time=   0.2s\n",
      "[CV 5/5] END ...................n_neighbors=208;, score=0.704 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=16;, score=0.829 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=208;, score=0.836 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=16;, score=0.853 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=208;, score=0.704 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=43;, score=0.853 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=43;, score=0.764 total time=   0.0s\n",
      "[CV 3/5] END ...................n_neighbors=394;, score=0.758 total time=   0.2s\n",
      "[CV 1/5] END ...................n_neighbors=347;, score=0.826 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=43;, score=0.824 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=43;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=394;, score=0.663 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=347;, score=0.764 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=347;, score=0.667 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=43;, score=0.838 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=381;, score=0.826 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=381;, score=0.758 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=347;, score=0.829 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=347;, score=0.689 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=180;, score=0.824 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=381;, score=0.662 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=462;, score=0.802 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=462;, score=0.667 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=180;, score=0.789 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=180;, score=0.838 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=381;, score=0.823 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=381;, score=0.681 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=180;, score=0.706 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=180;, score=0.709 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=64;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=64;, score=0.843 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=64;, score=0.748 total time=   0.0s\n",
      "[CV 1/5] END ...................n_neighbors=462;, score=0.823 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=462;, score=0.736 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=64;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=64;, score=0.741 total time=   0.0s\n",
      "[CV 5/5] END ...................n_neighbors=462;, score=0.658 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=353;, score=0.824 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=232;, score=0.838 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=242;, score=0.826 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=353;, score=0.762 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=232;, score=0.703 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=242;, score=0.784 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=242;, score=0.695 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=353;, score=0.667 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=53;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=353;, score=0.831 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=232;, score=0.699 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=232;, score=0.785 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=242;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=242;, score=0.703 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=232;, score=0.826 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=53;, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END ...................n_neighbors=353;, score=0.686 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=53;, score=0.757 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=97;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=53;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=97;, score=0.814 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=97;, score=0.728 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=53;, score=0.748 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=97;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=97;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END ...................n_neighbors=389;, score=0.821 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=223;, score=0.823 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=389;, score=0.681 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=389;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=223;, score=0.791 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=223;, score=0.697 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=223;, score=0.838 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=389;, score=0.758 total time=   0.2s\n",
      "[CV 2/5] END ...................n_neighbors=486;, score=0.796 total time=   0.2s\n",
      "[CV 5/5] END ...................n_neighbors=389;, score=0.663 total time=   0.2s\n",
      "[CV 4/5] END ...................n_neighbors=223;, score=0.704 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=408;, score=0.826 total time=   0.2s\n",
      "[CV 4/5] END ...................n_neighbors=486;, score=0.660 total time=   0.2s\n",
      "[CV 1/5] END ...................n_neighbors=486;, score=0.828 total time=   0.2s\n",
      "[CV 3/5] END ...................n_neighbors=408;, score=0.753 total time=   0.1s\n",
      "[CV 1/5] END ...................n_neighbors=232;, score=0.826 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=408;, score=0.676 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=408;, score=0.662 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=486;, score=0.731 total time=   0.2s\n",
      "[CV 2/5] END ...................n_neighbors=408;, score=0.818 total time=   0.1s\n",
      "[CV 2/5] END ...................n_neighbors=232;, score=0.838 total time=   0.1s\n",
      "[CV 3/5] END ...................n_neighbors=232;, score=0.785 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=486;, score=0.655 total time=   0.1s\n",
      "[CV 4/5] END ...................n_neighbors=232;, score=0.703 total time=   0.1s\n",
      "[CV 5/5] END ...................n_neighbors=232;, score=0.699 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(), n_iter=200,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;n_neighbors&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x11c490110&gt;},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(), n_iter=200,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;n_neighbors&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x11c490110&gt;},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(), n_iter=200,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'n_neighbors': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x11c490110>},\n",
       "                   random_state=42, scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Import data\n",
    "data = pd.read_csv('Data/biodiversity-prepared.csv')\n",
    "\n",
    "# X, y split\n",
    "X = data.drop(columns='RCACScore')\n",
    "y = data['RCACScore']\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "        'n_neighbors': randint(low=2, high=500)\n",
    "}\n",
    "\n",
    "# Random search using the appropriate values\n",
    "knn_rnd_search = RandomizedSearchCV(\n",
    "    KNeighborsClassifier(), \n",
    "    param_distributions = param_grid,\n",
    "    n_iter=200,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose = 5\n",
    ")\n",
    "\n",
    "# Fit this model\n",
    "knn_rnd_search.fit(X.values, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01d34c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of best performing model:  0.8232530754104358\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of best performing model: ', knn_rnd_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ceba2a",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    "\n",
    "In this exercise, we are going to use PCA to extract greater performances from our models on this small dataset. First, let's see how much of the explained variance each component would get us. When you do a PCA analysis, the principal components are sorted in order of their contribution to explaining the variance of your data. Component 1 is the most important, 2 is a bit less important, etc...the `pca` object contains an attribute that contains the %-contribution that each component makes to the variability of your data.\n",
    "\n",
    "In the first part of our exercise, we will try to plot this cumulative variance. Do the following:\n",
    "\n",
    "* Create a new `PCA` model and fit it with the features of the biodiversity dataset (in my case this is called `X`)\n",
    "* Create an empty array (a good name for it would be `explained_variance`)\n",
    "* Using a loop, add the cumulative sum of the explained variance from component 1 to the last component. You will need to take the sum of each component, gradually adding more components. Save your values in the array\n",
    "* Plot the % of explained variance (your array)\n",
    "\n",
    "What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4593568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create PCA model and fit it to X\n",
    "pca = PCA()\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f296a7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'explained variance')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We actually learned how to find cumulative sum without a loop in Lecture 2\n",
    "explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# More than 90% of the variance can be explained in less than 10 components!\n",
    "plt.plot(explained_variance);\n",
    "plt.xlabel('n of principal component')\n",
    "plt.ylabel('explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b2492",
   "metadata": {},
   "source": [
    "### Finding the best number of component and k for our algorithm\n",
    "\n",
    "Now let's see if PCA can help us get a few percent improvement in accuracy, using less features. Use a pipeline and `RandomizedSearchCV` to identify the best combination of `n_components` to use for our PCA object and the best value of `k` for a KNN classifier. What accuracy score do you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dd73d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA()),\n",
       "                                             (&#x27;knn&#x27;, KNeighborsClassifier())]),\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={&#x27;knn__n_neighbors&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000228E7F13AC0&gt;,\n",
       "                                        &#x27;pca__n_components&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000228EBE9DF90&gt;},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA()),\n",
       "                                             (&#x27;knn&#x27;, KNeighborsClassifier())]),\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={&#x27;knn__n_neighbors&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000228E7F13AC0&gt;,\n",
       "                                        &#x27;pca__n_components&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000228EBE9DF90&gt;},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA()), (&#x27;knn&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('pca', PCA()),\n",
       "                                             ('knn', KNeighborsClassifier())]),\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'knn__n_neighbors': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000228E7F13AC0>,\n",
       "                                        'pca__n_components': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000228EBE9DF90>},\n",
       "                   random_state=42, scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy our code from above\n",
    "\n",
    "knn_pipe = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'pca__n_components': randint(low=10, high=20),  # We try and find a n_components between 10 and 20 \n",
    "                                                    # since 14 represents 97% of the data\n",
    "    'knn__n_neighbors': randint(low=2, high=500)\n",
    "}\n",
    "\n",
    "# Random search using the appropriate values\n",
    "knn_rnd_search = RandomizedSearchCV(\n",
    "    knn_pipe, \n",
    "    param_distributions = param_grid,\n",
    "    n_iter=200,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose = 5\n",
    ")\n",
    "\n",
    "# Fit this model\n",
    "knn_rnd_search.fit(X.values, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1476a5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(n_components=17)),\n",
      "                ('knn', KNeighborsClassifier(n_neighbors=10))])\n",
      "0.827291695248548\n"
     ]
    }
   ],
   "source": [
    "# Very slight improvement...honestly not much better\n",
    "print(knn_rnd_search.best_estimator_)\n",
    "print(knn_rnd_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb41ba",
   "metadata": {},
   "source": [
    "### Trying the same approach with support vector machine\n",
    "\n",
    "Now let's try to combining PCA with support vector machines and see what accuracy we can get...Are the best parameters for this model the same as for the KNN with PCA approach?\n",
    "\n",
    "**Note**: Some combinations of SVC can take a long time to run - I recommend lowering the `n_iter` to around 20 in order to scope out the best/fastest models. Look up the `cv_results_` attribute of the `RandomizedSearchCV` object to get a breakdown of all the combinations the search attempted. **Hint**: Running `pd.DataFrame(search.cv_results_)` will automatically put all the information in a dataframe for easy reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b43be431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA()), (&#x27;svr&#x27;, SVC())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;pca__n_components&#x27;: [10, 11, 12, 13,\n",
       "                                                              14, 15, 16, 17,\n",
       "                                                              18, 19, 20],\n",
       "                                        &#x27;svr__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                                   1000, 10000],\n",
       "                                        &#x27;svr__kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;,\n",
       "                                                        &#x27;sigmoid&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA()), (&#x27;svr&#x27;, SVC())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;pca__n_components&#x27;: [10, 11, 12, 13,\n",
       "                                                              14, 15, 16, 17,\n",
       "                                                              18, 19, 20],\n",
       "                                        &#x27;svr__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                                   1000, 10000],\n",
       "                                        &#x27;svr__kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;,\n",
       "                                                        &#x27;sigmoid&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA()), (&#x27;svr&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('pca', PCA()), ('svr', SVC())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'pca__n_components': [10, 11, 12, 13,\n",
       "                                                              14, 15, 16, 17,\n",
       "                                                              18, 19, 20],\n",
       "                                        'svr__C': [0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                                   1000, 10000],\n",
       "                                        'svr__kernel': ['linear', 'rbf',\n",
       "                                                        'sigmoid']},\n",
       "                   random_state=42, scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create pipeline\n",
    "svr_pipe = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('svr', SVC()) # Remember to use SVC, not SVR - this is a classification problem!\n",
    "])\n",
    "\n",
    "# Set up parameter grid\n",
    "param_grid = {\n",
    "    'pca__n_components': [i for i in range(10,21)],\n",
    "    'svr__kernel': [\"linear\", \"rbf\", \"sigmoid\"],    \n",
    "    'svr__C': [10**i for i in range(-3, 5)] # this generates the following list: 0.001, 0.01, 0.1, ... 1000, 10000\n",
    "}\n",
    "\n",
    "# Set up the GridSearch with the SVR_pipe\n",
    "pca_searcher = RandomizedSearchCV(\n",
    "    svr_pipe,\n",
    "    param_distributions = param_grid, \n",
    "    n_iter = 20,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose = 5,\n",
    "    n_jobs = -1,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "pca_searcher.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d469e97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(n_components=20)),\n",
      "                ('svr', SVC(C=1, kernel='linear'))])\n",
      "0.9249788494077833\n"
     ]
    }
   ],
   "source": [
    "# Much better - 92% accuracy!\n",
    "print(pca_searcher.best_estimator_)\n",
    "print(pca_searcher.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7d40c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;svr&#x27;, SVC())]), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;svr__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                                   1000, 10000],\n",
       "                                        &#x27;svr__kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;,\n",
       "                                                        &#x27;sigmoid&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;svr&#x27;, SVC())]), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;svr__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                                   1000, 10000],\n",
       "                                        &#x27;svr__kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;,\n",
       "                                                        &#x27;sigmoid&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;svr&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=Pipeline(steps=[('svr', SVC())]), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'svr__C': [0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                                   1000, 10000],\n",
       "                                        'svr__kernel': ['linear', 'rbf',\n",
       "                                                        'sigmoid']},\n",
       "                   random_state=42, scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline\n",
    "svr_pipe = Pipeline([\n",
    "    ('svr', SVC()) # Remember to use SVC, not SVR - this is a classification problem!\n",
    "])\n",
    "\n",
    "# Set up parameter grid\n",
    "param_grid = {\n",
    "    'svr__kernel': [\"linear\", \"rbf\", \"sigmoid\"],    \n",
    "    'svr__C': [10**i for i in range(-3, 5)] # this generates the following list: 0.001, 0.01, 0.1, ... 1000, 10000\n",
    "}\n",
    "\n",
    "# Set up the GridSearch with the SVR_pipe\n",
    "nonpca_searcher = RandomizedSearchCV(\n",
    "    svr_pipe,\n",
    "    param_distributions = param_grid, \n",
    "    n_iter = 20,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose = 5,\n",
    "    n_jobs = -1,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "nonpca_searcher.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65096dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('svr', SVC(C=1000, kernel='linear'))])\n",
      "0.9266691818722276\n"
     ]
    }
   ],
   "source": [
    "# % accuracy without PCA\n",
    "print(nonpca_searcher.best_estimator_)\n",
    "print(nonpca_searcher.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89562a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
